{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "At the end of this lesson, you will be able to write TensorFlow and Keras code to use one of the best models in computer vision.\n",
    "\n",
    "# Lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://www.youtube.com/embed/sDG5tPtsbSA\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fee8415c160>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('sDG5tPtsbSA', width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Code\n",
    "Choose Images to Work With"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "image_dir = '../input/dog-breed-identification/train/'\n",
    "img_paths = [join(image_dir, filename) for filename in \n",
    "                           ['0246f44bb123ce3f91c939861eb97fb7.jpg',\n",
    "                            '84728e78632c0910a69d33f82e62638c.jpg',\n",
    "                            '8825e914555803f4c67b26593c9d5aff.jpg',\n",
    "                            '91a5e8db15bccfb6cfa2df5e8b95ec03.jpg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Read and Prep Images for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    output = preprocess_input(img_array)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model with Pre-Trained Weights File. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d1445adab314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_prep_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/tensorflow/python/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/tensorflow/python/keras/applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/keras_applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         raise ValueError('The `weights` argument should be either '\n\u001b[0m\u001b[1;32m    197\u001b[0m                          \u001b[0;34m'`None` (random initialization), `imagenet` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                          \u001b[0;34m'(pre-training on ImageNet), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded."
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "\n",
    "my_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "test_data = read_and_prep_images(img_paths)\n",
    "preds = my_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'learntools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b6324ccce77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlearntools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmost_likely_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_list_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../input/resnet50/imagenet_class_index.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'learntools'"
     ]
    }
   ],
   "source": [
    "from learntools.deep_learning.decode_predictions import decode_predictions\n",
    "from IPython.display import Image, display\n",
    "\n",
    "most_likely_labels = decode_predictions(preds, top=3, class_list_path='../input/resnet50/imagenet_class_index.json')\n",
    "\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    display(Image(img_path))\n",
    "    print(most_likely_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "## Intro\n",
    "The TV show *Silicon Valley* had an app called \"See Food\" that promised to identify food. \n",
    "\n",
    "In this notebook, you will write code using and comparing pre-trained models to choose one as an engine for the See Food app.\n",
    "\n",
    "You won't go too deep into Keras or TensorFlow details in this particular exercise.  Don't worry. You'll go deeper into model development soon.  For now, you'll make sure you know how to use pre-trained models.\n",
    "\n",
    "## Set-Up\n",
    "We will run a few steps of environmental set-up before writing your own code. **You don't need to understand the details of this set-up code.** You can just run each code cell until you get to the exercises.\n",
    "\n",
    "### 1) Create Image Paths\n",
    "This workspace includes image files you will use to test your models. Run the cell below to store a few filepaths to these images in a variable `img_paths`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "hot_dog_image_dir = '../input/hot-dog-not-hot-dog/seefood/train/hot_dog'\n",
    "\n",
    "hot_dog_paths = [join(hot_dog_image_dir,filename) for filename in \n",
    "                            ['1000288.jpg',\n",
    "                             '127117.jpg']]\n",
    "\n",
    "not_hot_dog_image_dir = '../input/hot-dog-not-hot-dog/seefood/train/not_hot_dog'\n",
    "not_hot_dog_paths = [join(not_hot_dog_image_dir, filename) for filename in\n",
    "                            ['823536.jpg',\n",
    "                             '99890.jpg']]\n",
    "\n",
    "img_paths = hot_dog_paths + not_hot_dog_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Run an Example Model\n",
    "Here is the code you saw in the tutorial. It loads data, loads a pre-trained model, and makes predictions. Run this cell too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'learntools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-474554953257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlearntools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'learntools'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from learntools.deep_learning.decode_predictions import decode_predictions\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    output = preprocess_input(img_array)\n",
    "    return(output)\n",
    "\n",
    "\n",
    "my_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "test_data = read_and_prep_images(img_paths)\n",
    "preds = my_model.predict(test_data)\n",
    "\n",
    "most_likely_labels = decode_predictions(preds, top=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m         \u001b[0;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m         \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'most_likely_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-84285a99bbed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_likely_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'most_likely_labels' is not defined"
     ]
    }
   ],
   "source": [
    "for i, img_path in enumerate(img_paths):\n",
    "    display(Image(img_path))\n",
    "    print(most_likely_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Set Up Code Checking\n",
    "As a last step before writing your own code, run the following cell to enable feedback on your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "You will write a couple useful functions in the next exercises. Then you will put these functions together to compare the effectiveness of various pretrained models for your hot-dog detection program.\n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "We want to distinguish whether an image is a hot dog or not. But our models classify pictures into 1000 different categories. Write a function that takes the models predictions (in the same format as `preds` from the set-up code) and returns a list of `True` and `False` values.\n",
    "\n",
    "Some tips:\n",
    "- Work iteratively. Figure out one line at a time outsie the function, and print that line's output to make sure it's right. Once you have all the code you need, move it into the function `is_hot_dog`. If you get an error, check that you have copied the right code and haven't left anything out.\n",
    "- The raw data we loaded in `img_paths` had two images of hot dogs, followed by two images of other foods. So, if you run your function on `preds`, which represents the output of the model on these images, your function should return `[True, True, False, False]`.\n",
    "- You will want to use the `decode_predictions` function that was also used in the code provided above. We provided a line with this in the code cell to get you started.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_hot_dog(preds):\n",
    "    \n",
    "    decoded = decode_predictions(preds, top=1)\n",
    "    '''\n",
    "    inputs:\n",
    "    preds_array:  array of predictions from pre-trained model\n",
    "\n",
    "    outputs:\n",
    "    is_hot_dog_list: a list indicating which predictions show hotdog as the most likely label\n",
    "    '''\n",
    "    is_hot_dog_list = []\n",
    "    for item in decoded:\n",
    "        if item[0][1] == \"hotdog\":\n",
    "            is_hot_dog_list.append(True)\n",
    "        else:\n",
    "            is_hot_dog_list.append(False)\n",
    "    return is_hot_dog_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Evaluate Model Accuracy\n",
    "\n",
    "You have a model (called `my_model`). Is it good enough to build your app around? \n",
    "\n",
    "Find out by writing a function that calculates a model's accuracy (fraction correct). You will try an alternative model in the next step. So we will put this logic in a reusable function that takes data and the model as arguments, and returns the accuracy.\n",
    "\n",
    "Tips:\n",
    "\n",
    " - Use the `is_hot_dog` function from above to help write your function\n",
    " - To save you some scrolling, here is the code from above where we used a TensorFlow model to make predictions:\n",
    "\n",
    "```\n",
    "my_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "test_data = read_and_prep_images(img_paths)\n",
    "preds = my_model.predict(test_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-55585ccd7399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Code to call calc_accuracy.  my_model, hot_dog_paths and not_hot_dog_paths were created in the setup code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_prep_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/tensorflow/python/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/tensorflow/python/keras/applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/keras_applications/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         raise ValueError('The `weights` argument should be either '\n\u001b[0m\u001b[1;32m    197\u001b[0m                          \u001b[0;34m'`None` (random initialization), `imagenet` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                          \u001b[0;34m'(pre-training on ImageNet), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded."
     ]
    }
   ],
   "source": [
    "def calc_accuracy(model, paths_to_hotdog_images, paths_to_other_images):\n",
    "    # We'll use the counts for denominator of accuracy calculation\n",
    "    num_hot_dog_images = len(paths_to_hotdog_images)\n",
    "    num_other_images = len(paths_to_other_images)\n",
    "\n",
    "    hotdog_image_data = read_and_prep_images(paths_to_hotdog_images)\n",
    "    preds_for_hotdogs = model.predict(hotdog_image_data)\n",
    "    # Summing list of binary variables gives a count of True values\n",
    "    num_correct_hotdog_preds = sum(is_hot_dog(preds_for_hotdogs))\n",
    "\n",
    "    other_image_data = read_and_prep_images(paths_to_other_images)\n",
    "    preds_other_images = model.predict(other_image_data)\n",
    "    # Number correct is the number judged not to be hot dogs\n",
    "    num_correct_other_preds = num_other_images - sum(is_hot_dog(preds_other_images))\n",
    "\n",
    "    total_correct = num_correct_hotdog_preds + num_correct_other_preds\n",
    "    total_preds = num_hot_dog_images + num_other_images\n",
    "    return total_correct / total_preds\n",
    "\n",
    "\n",
    "\n",
    "# Code to call calc_accuracy.  my_model, hot_dog_paths and not_hot_dog_paths were created in the setup code\n",
    "\n",
    "my_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "test_data = read_and_prep_images(img_paths)\n",
    "preds = my_model.predict(test_data)\n",
    "\n",
    "\n",
    "\n",
    "my_model_accuracy = calc_accuracy(my_model, hot_dog_paths, not_hot_dog_paths)\n",
    "print(\"Fraction correct in small test set: {}\".format(my_model_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "There are other models besides the ResNet model (which we have loaded). For example, an earlier winner of the ImageNet competition is the VGG16 model.  Don't worry about the differences between these models yet. We'll come back to that later. For now, just focus on the mechanics of applying these models to a problem.\n",
    "\n",
    "The code used to load a pretrained ResNet50 model was\n",
    "\n",
    "```\n",
    "my_model = ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "```\n",
    "\n",
    "The weights for the model are stored at `../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5`.\n",
    "\n",
    "In the cell below, create a VGG16 model with the preloaded weights. Then use your `calc_accuracy` function to determine what fraction of images the VGG16 model correctly classifies.  Is it better or worse than the pretrained ResNet model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-febac772e316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvgg16_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# calculate accuracy on small dataset as a test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvgg16_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhot_dog_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnot_hot_dog_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/tensorflow/python/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/tensorflow/python/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda/lib/python3.7/site-packages/keras_applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         raise ValueError('The `weights` argument should be either '\n\u001b[0m\u001b[1;32m     86\u001b[0m                          \u001b[0;34m'`None` (random initialization), `imagenet` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                          \u001b[0;34m'(pre-training on ImageNet), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded."
     ]
    }
   ],
   "source": [
    "# import the model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg16_model = VGG16(weights='../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "# calculate accuracy on small dataset as a test\n",
    "vgg16_accuracy = calc_accuracy(vgg16_model, hot_dog_paths, not_hot_dog_paths)\n",
    "\n",
    "print(\"Fraction correct in small dataset: {}\".format(vgg16_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
